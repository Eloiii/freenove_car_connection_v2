{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorrt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('car_data.csv')\n",
    "print(raw_df.shape)\n",
    "raw_df.head(100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SoC_forecasting_model(timesteps, features, batch_size, output_shape, dropout=0, recurrent_dropout=0, verbose=True):\n",
    "    \"\"\"\n",
    "    cuDNN Requirements\n",
    "    activation == tanh\n",
    "    recurrent_activation == sigmoid\n",
    "    recurrent_dropout == 0\n",
    "    unroll is False\n",
    "    use_bias is True\n",
    "    \"\"\"\n",
    "    STATEFUL = True\n",
    "    SoC_model = Sequential(name ='SoC_Forecasting_Model')\n",
    "    SoC_model.add(LSTM(16, input_shape=(timesteps, features), batch_size=batch_size, dropout=dropout, recurrent_dropout=recurrent_dropout, return_sequences=True, stateful=STATEFUL, name='LSTM_1'))\n",
    "\n",
    "    SoC_model.add(LSTM(32, dropout=dropout, recurrent_dropout=recurrent_dropout, return_sequences=True, stateful=STATEFUL, name='LSTM_2'))\n",
    "    #SoC_model.add(LSTM(16, dropout=dropout, recurrent_dropout=recurrent_dropout, return_sequences=True, stateful=STATEFUL, name='LSTM_hidden2'))\n",
    "\n",
    "\n",
    "    SoC_model.add(LSTM(16, dropout=dropout, recurrent_dropout=recurrent_dropout, stateful=STATEFUL, name='LSTM_last'))\n",
    "    SoC_model.add(Dense(output_shape, name='Dense_output'))\n",
    "    SoC_model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    if verbose :\n",
    "        print(SoC_model.summary())\n",
    "    return SoC_model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def AIO_preprocess_train_SoC_model(df, look_back=32, look_ahead=1, test_size=0.2, epochs=50, batch_size=256, verbose=True, evaluate=True):\n",
    "\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_Y = MinMaxScaler()\n",
    "\n",
    "    df.astype(float)\n",
    "\n",
    "    #df['voltage_smoothed'] = df['voltage']\n",
    "    df['voltage_smoothed'] = df['voltage'].ewm(alpha=0.1, adjust=False).mean()\n",
    "    df['voltage_smoothed'] = df['voltage_smoothed'].fillna(df['voltage'])\n",
    "\n",
    "\n",
    "    raw_X = df.drop(['timestamp', 'voltage'], axis=1)\n",
    "\n",
    "    raw_Y = np.array(df['voltage_smoothed'])\n",
    "\n",
    "    raw_X = scaler_X.fit_transform(raw_X)\n",
    "    raw_Y = scaler_Y.fit_transform(raw_Y.reshape(-1,1))\n",
    "    raw_Y = raw_Y.reshape(-1)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(np.array(raw_X), np.array(raw_Y), test_size=test_size, shuffle=False)\n",
    "    model = SoC_forecasting_model(look_back, X_train.shape[1], batch_size, look_ahead, dropout=0, verbose=verbose)\n",
    "    if verbose :\n",
    "        print('X_train  :',X_train.shape)\n",
    "        print('Y_train  :',Y_train.shape)\n",
    "        print('X_test   :',X_test.shape)\n",
    "        print('Y_test   :',Y_test.shape)\n",
    "\n",
    "    mse_train = []\n",
    "    mae_train = []\n",
    "    mse_test = []\n",
    "    mae_test = []\n",
    "    if verbose :\n",
    "        print(f'{\"TRAINING\":-^100}')\n",
    "    for i in range(epochs):\n",
    "        for j in tqdm(range((X_train.shape[0]-look_ahead-look_back)//batch_size), ncols=100, desc=f\"Epoch: {i+1:0>{len(str(epochs))}}/{epochs:0>{len(str(epochs))}}\", colour='green', disable=not verbose):\n",
    "            X_batch = np.empty((batch_size, look_back, X_train.shape[1]))\n",
    "            Y_batch = np.empty((batch_size, look_ahead))\n",
    "            for k in range(j*batch_size, (j+1)*batch_size):\n",
    "                X_batch[k - j*batch_size] = X_train[k : k + look_back]\n",
    "                Y_batch[k - j*batch_size] = Y_train[k + look_back : k + look_back + look_ahead]\n",
    "            metrics = model.train_on_batch(X_batch, Y_batch, reset_metrics=False)\n",
    "            mse_train.append(metrics[0])\n",
    "            mae_train.append(metrics[1])\n",
    "        model.reset_states()\n",
    "\n",
    "    if verbose :\n",
    "        plt.plot(mse_train, label='mse')\n",
    "        plt.plot(mae_train, label='mae')\n",
    "        plt.title('Training stats')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    if evaluate :\n",
    "        if verbose :\n",
    "            print(f'{\"EVALUATION\":-^100}')\n",
    "        for j in tqdm(range((X_test.shape[0]-look_ahead-look_back)//batch_size), ncols=100, desc='Evaluation', colour='red', disable=not verbose):\n",
    "            X_batch = np.empty((batch_size, look_back, X_test.shape[1]))\n",
    "            Y_batch = np.empty((batch_size, look_ahead))\n",
    "            for k in range(j*batch_size, (j+1)*batch_size):\n",
    "                X_batch[k - j*batch_size] = X_test[k : k + look_back]\n",
    "                Y_batch[k - j*batch_size] = Y_test[k + look_back : k + look_back + look_ahead]\n",
    "            metrics = model.test_on_batch(X_batch, Y_batch)\n",
    "            mse_test.append(metrics[0])\n",
    "            mae_test.append(metrics[1])\n",
    "        if verbose :\n",
    "            plt.plot(mse_test, label='mse')\n",
    "            plt.plot(mae_test, label='mae')\n",
    "            plt.title('Testing stats')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    return model, scaler_X, scaler_Y, X_train, X_test, Y_train, Y_test\n",
    "\n",
    "model, scaler_X, scaler_Y, X_train, X_test, Y_train, Y_test = AIO_preprocess_train_SoC_model(raw_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res =[]\n",
    "look_back=32\n",
    "look_ahead=1\n",
    "batch_size=256\n",
    "for j in tqdm(range((X_test.shape[0]-look_back-look_ahead)//batch_size), ncols=100, desc='Prediction', colour='blue'):\n",
    "    X_batch = np.empty((batch_size, look_back, X_test.shape[1]))\n",
    "    for k in range(j*batch_size, (j+1)*batch_size):\n",
    "        X_batch[k - j*batch_size] = X_test[k : k + look_back]\n",
    "    Y_batch = model.predict_on_batch(X_batch)\n",
    "    res.extend(Y_batch.reshape(-1))\n",
    "plt.plot(res, label='prediction')\n",
    "plt.plot(Y_test, label='real')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
