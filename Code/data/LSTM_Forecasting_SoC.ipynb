{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('car_data.csv')\n",
    "print(raw_df.shape)\n",
    "raw_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Good performances with:\n",
    "\n",
    "LSTM : 16/32/16 | Timesteps 32 | Lookahead 1 | Batch Size : 256 | Dropout X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SoC_forecasting_model(timesteps, features, batch_size, output_shape, dropout=0, recurrent_dropout=0, verbose=True):\n",
    "    \"\"\"\n",
    "    - cuDNN Requirements\n",
    "    activation == tanh\n",
    "    recurrent_activation == sigmoid\n",
    "    recurrent_dropout == 0\n",
    "    unroll is False\n",
    "    use_bias is True\n",
    "    - All those are default values\n",
    "    \"\"\"\n",
    "    STATEFUL = True\n",
    "    SoC_model = Sequential(name ='SoC_Forecasting_Model')\n",
    "    SoC_model.add(Input(shape=(timesteps, features), batch_size=batch_size, name='Input'))\n",
    "    SoC_model.add(LSTM(16, dropout=dropout, recurrent_dropout=recurrent_dropout, stateful=STATEFUL, name='LSTM_1', return_sequences=True))\n",
    "    SoC_model.add(LSTM(32, dropout=dropout, recurrent_dropout=recurrent_dropout, stateful=STATEFUL, name='LSTM_2', return_sequences=True))\n",
    "    SoC_model.add(LSTM(16, dropout=dropout, recurrent_dropout=recurrent_dropout, stateful=STATEFUL, name='LSTM_last'))\n",
    "    SoC_model.add(Dense(output_shape, name='Dense_output'))\n",
    "    SoC_model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    if verbose :\n",
    "        print(SoC_model.summary())\n",
    "    return SoC_model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def AIO_preprocess_train_SoC_model2(raw_df, look_back=32, look_ahead=1, batch_size=256, test_size=0.2, epochs=20, verbose=True):\n",
    "\n",
    "    df = raw_df.copy()\n",
    "\n",
    "    scaler_features = MinMaxScaler()\n",
    "    scaler_voltage = MinMaxScaler()\n",
    "\n",
    "    # Pre-process of data\n",
    "    # Reduce noise in voltage measures\n",
    "    # Transform timestamps into cycles number\n",
    "    THRESHOLD = 1000\n",
    "    df['diff_time'] = df['timestamp'].diff()\n",
    "    df['diff_time'] = df['diff_time'].abs()\n",
    "    df['cycle'] = (df['diff_time'] > THRESHOLD).cumsum()\n",
    "    df['timestamp'] = df['timestamp'] - df.groupby('cycle')['timestamp'].transform('min')\n",
    "    df['voltage_smoothed'] = df['voltage'].ewm(alpha=0.1, adjust=False).mean()\n",
    "    df['voltage_smoothed'] = df['voltage_smoothed'].fillna(df['voltage'])\n",
    "    df.drop(['voltage','timestamp','diff_time'], axis=1, inplace=True)\n",
    "\n",
    "    # Split into features and target\n",
    "    # Scale features and target\n",
    "    df_voltage = df['voltage_smoothed']\n",
    "    df_cycle = df['cycle']\n",
    "    df.drop(['cycle'], axis=1, inplace=True)\n",
    "    columns = df.columns.tolist()\n",
    "\n",
    "    df = pd.DataFrame(scaler_features.fit_transform(df), columns=columns)\n",
    "    df_voltage = pd.DataFrame(scaler_voltage.fit_transform(df_voltage.values.reshape(-1,1)), columns=['voltage'])\n",
    "\n",
    "    df = pd.concat([df_cycle, df], axis=1)\n",
    "    df_voltage = pd.concat([df_cycle, df_voltage], axis=1)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(np.array(df), np.array(df_voltage), test_size=test_size, shuffle=False)\n",
    "    columns.insert(0,'cycle')\n",
    "    X_train = pd.DataFrame(X_train, columns=columns)\n",
    "    X_test = pd.DataFrame(X_test, columns=columns)\n",
    "    Y_train = pd.DataFrame(Y_train, columns=['cycle','voltage'])\n",
    "    Y_test = pd.DataFrame(Y_test, columns=['cycle','voltage'])\n",
    "\n",
    "    X_train_gp = X_train.groupby('cycle')\n",
    "    Y_train_gp = Y_train.groupby('cycle')\n",
    "    mse_train = []\n",
    "    mae_train = []\n",
    "\n",
    "    if verbose :\n",
    "        print('Training set size  :',X_train.shape[0])\n",
    "        print('Test set size      :',X_test.shape[0])\n",
    "\n",
    "    model = SoC_forecasting_model(look_back, X_train.shape[1]-1, batch_size, look_ahead, verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "    if verbose :\n",
    "        print(f'{\"TRAINING\":-^100}')\n",
    "    for epoch in range(epochs):\n",
    "        for i in X_train_gp.groups.keys():\n",
    "\n",
    "            X = np.delete(X_train_gp.get_group(i).values, 0, axis=1)\n",
    "            Y = np.delete(Y_train_gp.get_group(i).values, 0, axis=1)\n",
    "            Y = np.append(Y, np.zeros(look_ahead)) # Padding\n",
    "            X_batchs = []\n",
    "            Y_batchs = []\n",
    "            for j in range(look_back, len(X)):\n",
    "                X_batchs.append(X[j-look_back:j])\n",
    "                Y_batchs.append(Y[j:j+look_ahead])\n",
    "            X_batchs = np.array(X_batchs)\n",
    "            Y_batchs = np.array(Y_batchs)\n",
    "            for k in range(len(X_batchs)//batch_size):\n",
    "                X_batch = X_batchs[k*batch_size : (k+1)*batch_size]\n",
    "                Y_batch = Y_batchs[k*batch_size : (k+1)*batch_size]\n",
    "                metrics = model.train_on_batch(X_batch, Y_batch, reset_metrics=False)\n",
    "                mse_train.append(metrics[0])\n",
    "                mae_train.append(metrics[1])\n",
    "\n",
    "            model.reset_states()\n",
    "    plt.plot(mse_train, label='mse')\n",
    "    plt.plot(mae_train, label='mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return model, scaler_features, scaler_voltage, X_train, X_test, Y_train, Y_test\n",
    "\n",
    "model, scaler_X, scaler_Y, X_train, X_test, Y_train, Y_test = AIO_preprocess_train_SoC_model2(raw_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def AIO_preprocess_test_SoC_model2(model, X_test, Y_test, look_back=32, look_ahead=1, batch_size=256, verbose=True):\n",
    "\n",
    "    X_test_gp = X_test.groupby('cycle')\n",
    "    Y_test_gp = Y_test.groupby('cycle')\n",
    "    mse_test = []\n",
    "    mae_test = []\n",
    "\n",
    "    if verbose :\n",
    "        print(f'{\"TESTING\":-^100}')\n",
    "    for i in X_test_gp.groups.keys():\n",
    "        X = np.delete(X_test_gp.get_group(i).values, 0, axis=1)\n",
    "        Y = np.delete(Y_test_gp.get_group(i).values, 0, axis=1)\n",
    "        Y = np.append(Y, np.zeros(look_ahead)) # Padding\n",
    "        X_batchs = []\n",
    "        Y_batchs = []\n",
    "        for j in range(look_back, len(X)):\n",
    "            X_batchs.append(X[j-look_back:j])\n",
    "            Y_batchs.append(Y[j:j+look_ahead])\n",
    "        X_batchs = np.array(X_batchs)\n",
    "        Y_batchs = np.array(Y_batchs)\n",
    "        for k in range(len(X_batchs)//batch_size):\n",
    "            X_batch = X_batchs[k*batch_size : (k+1)*batch_size]\n",
    "            Y_batch = Y_batchs[k*batch_size : (k+1)*batch_size]\n",
    "            metrics = model.test_on_batch(X_batch, Y_batch, reset_metrics=False)\n",
    "            mse_test.append(metrics[0])\n",
    "            mae_test.append(metrics[1])\n",
    "\n",
    "    plt.plot(mse_test, label='mse')\n",
    "    plt.plot(mae_test, label='mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return mse_test, mae_test\n",
    "\n",
    "mse_test, mae_test = AIO_preprocess_test_SoC_model2(model, X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(model, X_input):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def AIO_preprocess_train_SoC_model(df, look_back=32, look_ahead=1, test_size=0.2, epochs=20, batch_size=256, verbose=True, evaluate=True):\n",
    "\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_Y = MinMaxScaler()\n",
    "\n",
    "    df.astype(float)\n",
    "\n",
    "    df['voltage_smoothed'] = df['voltage'].ewm(alpha=0.1, adjust=False).mean()\n",
    "    df['voltage_smoothed'] = df['voltage_smoothed'].fillna(df['voltage'])\n",
    "\n",
    "    raw_X = df.drop(['timestamp', 'voltage'], axis=1)\n",
    "    raw_Y = np.array(df['voltage_smoothed'])\n",
    "\n",
    "    raw_X = scaler_X.fit_transform(raw_X)\n",
    "    raw_Y = scaler_Y.fit_transform(raw_Y.reshape(-1,1))\n",
    "    raw_Y = raw_Y.reshape(-1)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(np.array(raw_X), np.array(raw_Y), test_size=test_size, shuffle=False)\n",
    "    model = SoC_forecasting_model(look_back, X_train.shape[1], batch_size, look_ahead, dropout=0, verbose=verbose)\n",
    "    if verbose :\n",
    "        print('X_train  :',X_train.shape)\n",
    "        print('Y_train  :',Y_train.shape)\n",
    "        print('X_test   :',X_test.shape)\n",
    "        print('Y_test   :',Y_test.shape)\n",
    "\n",
    "    mse_train = []\n",
    "    mae_train = []\n",
    "    mse_test = []\n",
    "    mae_test = []\n",
    "    if verbose :\n",
    "        print(f'{\"TRAINING\":-^100}')\n",
    "    for i in range(epochs):\n",
    "        for j in tqdm(  range((X_train.shape[0]-look_ahead-look_back)//batch_size)  , desc=f\"Epoch: {i+1:0>{len(str(epochs))}}/{epochs:0>{len(str(epochs))}}\", colour='green', disable=not verbose):\n",
    "            X_batch = np.empty((batch_size, look_back, X_train.shape[1]))\n",
    "            Y_batch = np.empty((batch_size, look_ahead))\n",
    "            for k in range(j*batch_size, (j+1)*batch_size):\n",
    "                X_batch[k - j*batch_size] = X_train[k : k + look_back]\n",
    "                Y_batch[k - j*batch_size] = Y_train[k + look_back : k + look_back + look_ahead]\n",
    "            metrics = model.train_on_batch(X_batch, Y_batch, reset_metrics=False)\n",
    "            mse_train.append(metrics[0])\n",
    "            mae_train.append(metrics[1])\n",
    "        model.reset_states()\n",
    "\n",
    "    if verbose :\n",
    "        plt.plot(mse_train, label='mse')\n",
    "        plt.plot(mae_train, label='mae')\n",
    "        plt.title('Training stats')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    if evaluate :\n",
    "        if verbose :\n",
    "            print(f'{\"EVALUATION\":-^100}')\n",
    "        for j in tqdm(range((X_test.shape[0]-look_ahead-look_back)//batch_size), desc='Evaluation', colour='red', disable=not verbose):\n",
    "            X_batch = np.empty((batch_size, look_back, X_test.shape[1]))\n",
    "            Y_batch = np.empty((batch_size, look_ahead))\n",
    "            for k in range(j*batch_size, (j+1)*batch_size):\n",
    "                X_batch[k - j*batch_size] = X_test[k : k + look_back]\n",
    "                Y_batch[k - j*batch_size] = Y_test[k + look_back : k + look_back + look_ahead]\n",
    "            metrics = model.test_on_batch(X_batch, Y_batch, reset_metrics=False)\n",
    "            mse_test.append(metrics[0])\n",
    "            mae_test.append(metrics[1])\n",
    "        if verbose :\n",
    "            plt.plot(mse_test, label='mse')\n",
    "            plt.plot(mae_test, label='mae')\n",
    "            plt.title('Testing stats')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    return model, scaler_X, scaler_Y, X_train, X_test, Y_train, Y_test\n",
    "\n",
    "model, scaler_X, scaler_Y, X_train, X_test, Y_train, Y_test = AIO_preprocess_train_SoC_model(raw_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res =[]\n",
    "look_back=32\n",
    "look_ahead=1\n",
    "batch_size=256\n",
    "for j in tqdm(range((X_test.shape[0]-look_back-look_ahead)//batch_size), ncols=100, desc='Prediction', colour='blue'):\n",
    "    X_batch = np.empty((batch_size, look_back, X_test.shape[1]))\n",
    "    for k in range(j*batch_size, (j+1)*batch_size):\n",
    "        X_batch[k - j*batch_size] = X_test[k : k + look_back]\n",
    "    Y_batch = model.predict_on_batch(X_batch)\n",
    "    res.extend(Y_batch.reshape(-1))\n",
    "plt.plot(res, label='prediction')\n",
    "plt.plot(Y_test, label='real')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
